---
title: 'R Notebook TP 3: Regresión Logística'
author: "Gustavo Arturo Ríos Páez"
date: "30 de Novienmbre de 2020"
output:
  html_document:
    df_print: paged
---

CONSIGNAS
En este trabajo deberán crear un modelo de regresión logística para clasificar si una persona que viajaba a bordo del Titanic sobrevivió o no.


```{r, message = FALSE, warning = FALSE}
rm( list=ls() )  #remove all objects
gc()             #garbage collection
#Añado librerías necesarias
library(tidyverse)
library(corrr)
library(ggplot2)
library(dplyr)
library(GGally)
library(tibble)
library(broom)
library(modelr)
library(ISLR)
library(pROC)
library(cowplot)
library(OneR)
library(rlang)
library(caret)
library(rsample)
#install.packages('e1071', dependencies=TRUE)
library(e1071)
set.seed(1988)

```


DATASET DE ENTRENAMIENTO:
1) Preparación de datos
a.Leer el archivo titanic_complete_train.csv y mostrar su estructura.

```{r}
#Leo los datos del dataSet 
titanic_train <- read.csv("titanic_complete_train.csv")
#Revisión datos con str
#str(titanic_train)
#Revisión datos con Glipse
glimpse(titanic_train)
#Clase de los datos
```

El data set cuenta con 891 observaciones y 12 variables, tenemos el id del pasajero, una variable dicotómica llamada Survived que define si sobrevivió o no. Una variable de la clase del pasajero Pclass acorde a la clasificación del barco en 1ra clase,2da clase,3ra clase, una variable de nombre Name, otra de género del pasajero Sex, una variable de edad Age, dos variables que cuentan la cantidad de familiares en el barco, estas son SibSp y Parch. Otra variable Ticket para el número de ticket, otra variable de Fare para el costo del ticket, una variable de cabina para definir la cabina en la que estaba el pasajero, y una variable embarqued que define el puerto donde embarcó el pasajero. 

```{r}
summary(titanic_train)
```

El resumen del dataset con summary nos aporta información interesante, en el mean de la variable survived vemos que sobrevivieron poco más del 38% de los pasajeros. La edad de los pasajeros oscila entre menos de un año y 80 años, siendo la media de los pasajeros 29 años. Las variables de SibSp y Parch nos muestran que en su mayoría los grupos familiares a bordo son pequeños con algunas exepciones evidenciadas por el número máximo. La variable Fare muestra un valor extremo en su máximo, en caso de ser interesante para la predicción, lo analizaremos más adelante.

b.Seleccionar las variables PassengerId, Survived, Pclass, Sex, Age, SibSp,Parch, Fare y Embarked.

Para esto usamos la función select:

```{r}
titanic_train_filter <- titanic_train %>% 
  select(PassengerId, Survived, Pclass, Sex, Age, SibSp,Parch, Fare, Embarked)
titanic_train_filter
```

c.Transformar las variables Survived, Pclass y Embarked a factor.

Para esto usamos la función mutate de tidyverse.

```{r}
titanic_train_filter <- titanic_train_filter %>% 
  mutate(Survived = factor(Survived), Pclass = factor(Pclass), Embarked = factor(Embarked))
titanic_train_filter
```
d.Realizar un gráfico de ggpairs para las variables Survived, Pclass, Sex, Age y Fare e interpretarlo.

Antes de graficar vemos un poco más en detalle la variable Fare, que cuenta con outliers severos:

```{r}
summary(titanic_train_filter$Fare)
titanic_train_filter %>% filter(Fare > 300)
```
Establecemos un punto de corte "300" para estos 3 outliers severos, lo que permitirá generar gráficos más claros.

Realizar un gráfico de ggpairs para las variables Survived, Pclass, Sex, Age y Fare e interpretarlo.

```{r, message = FALSE, warning = FALSE}
titanic_train_filter %>% 
  select(Survived, Pclass, Sex, Age, Fare) %>% #Filtramos por las variables
  #select(Survived, Pclass, Sex) %>% #Filtramos por las variables
  filter(Fare < 300) %>% #Filtramos por el punto de corte definido
  ggpairs(., title = "GG Pairs Titanic",
  labeller = "label_value",
  mapping = aes(colour = Survived)) #Coloreamos separando los sobrevivientes de los que no sobrevivieron
```


Coloreamos las gráficas por la variable survived, en rojo tenemos los fallecidos, en azul los sobrevivientes.
La columna de survived nos muestra que son menos los sobrevivientes que las personas fallecidas. Cuando vemos la gráfica de Pclass vs survived, vemos que en 1ra clase tenemos más sobrevivientes que fallecidos, y que en 3ra clase tenemos una gran cantidad de fallecidos respecto a los sobrevibientes.

La gráfica de Sex vs Survived nos muestra que se tiene una mayor tasa de sobrevivencia entre las mujeres frente a los hombres.
La gráfica de Age vs. Survived nos muestra una distribución normal con cola larga a la derecha, en ambos casos la distribución de nuestra variable survived es muy similar, con lo que no pareciera haber una correlación entre estas dos variables.

La gráfica de Fare vs. Survided nos muestra que en general las personas que se salvaron pagaron un fare superior a las que fallecieron, esto lo podemos ver también en la gráfica de Fare vs. PClass, donde vemos que para 1ra clase hay una tasa más grande de personas que sobrevivieron frente a las que no, en 2da y 3ra clase vemos mucho más similar la distridución en los casos de sobreviviente frente a no sobreviviente.

La gráfica de PClass vs. Sex nos muestra que la mayoría de víctimas fueron hombres de 3ra clase, además podemos ver que una gran mayoría de mujeres de primera y segunda clase se salvaron, en 3ra clase gráficamente vemos que se salvaron alrededor de la mitad de las mujeres.

e.Mostrar la distribución de clase (Sobrevivientes vs No Sobrevivientes).

Primero vemos un resumen de la variable:

```{r}
summary(titanic_train_filter$Survived)
```
Vemos que se tienen 549 personas fallecidas y 342 que sobrevivieron. Lo que sería un 62% de fallecidos frente a un 38% de sobrevivientes.

f.Dividir al dataset en conjunto de entrenamiento (70% de los datos) y validación (30% de los datos). Volver a analizar la distribución de clase para chequear que sea aproximadamente igual entre ambos conjuntos y respecto a la distribución de clase que obtuvieron para todo el dataset en el punto 1)e).

NOTA: Ya hemos imputado los valores faltantes de ciertas variables en este dataset

```{r}
#Fijamos semilla
set.seed(1988)
#Partición Train y Test, indicando proporción
titanic_train_test <- createDataPartition(titanic_train_filter$Survived, p = .7, list = FALSE)
#Armamos dataframe de testeo y entrenamiento estratificados
titanic_split_train <- titanic_train_filter[ titanic_train_test,]
titanic_split_test  <- titanic_train_filter[-titanic_train_test,]

#Titanic Split Train
summary(titanic_split_train$Survived)
#Titanic Split Test
summary(titanic_split_test$Survived)
```

Vemos con el método estratificado una proporción como la dataset antes de su partición, con un 62% de fallecidos. 

2) Predicciones
a.Realizar un modelo de regresión logística para predecir la supervivencia en función de Pclass, Sex y Age. Usar solo el dataset de entrenamiento.

Creamos primero el objeto de fórmulas para este modelo
```{r}
logit_formulas <- formulas(.response = ~ Survived, # único lado derecho de las formulas.
                         pClassSexAge = ~ Pclass + Sex + Age 
                         )
logit_formulas # observamos el objeto formulas
```

Ahora creamos el modelo basados en las 3 variables:

```{r, message = FALSE, warning = FALSE}
models <- data_frame(logit_formulas) %>% # dataframe a partir del objeto formulas
  mutate(models = names(logit_formulas), # columna con los nombres de las formulas
         expression = paste(logit_formulas), # columna con las expresiones de las formulas
         mod = map(logit_formulas, ~glm(., family = 'binomial', data = titanic_split_train))) 
models
```
Ahora para desanidar la columna mod:

```{r}
models %>% 
  mutate(tidy = map(mod, tidy)) %>% 
  unnest(tidy) %>% 
  mutate(estimate=round(estimate,5), # redondeamos valores para facilitar lectura
         p.value=round(p.value,4))
```


b.Dar una breve interpretación de los coeficientes y su significatividad.


Para este modelo vemos que acorde al p-valor todos los coeficientes son significativos. Debemos tener en cuenta que las variables no tienen una relación lineal con la probabilidad, dado que trabajamos una regresión logística.
La variable basal de clase es "1ra clase", y la de sexo es "female".


Los estimados de las otras variables de este modelo, son todos negativos, con lo que las probabilidades de sobrevivir disminuyen si se es de la variable dummy 2da clase (dadas las demás variables), y disminuyen aún más si se es de 3ra clase  (dadas las demás variables), el ser de 3ra clase disminuye las probabilidades casi del mismo modo que ser hombre (dadas las demás variables). A medida que la edad aumenta también disminuye la probabilidad de salvarse.


c.¿Quién tiene una mayor probabilidad de supervivencia? Rose que es una mujer de 17 años que viaja en primera clase o Jack que es un hombre de 20 años viajando en tercera clase.

Acorde al modelo Rose tiene una mayor probabilidad de supervivencia, dado que:
Es mujer, y Jack al ser hombre cuenta con el estimado de -2.48.
Viaja en 1ra clase, frente a la 3ra clase de Jack, que cuenta con el estimado de -2.48.
Tiene 17 años frente a los 20 de Jack, y acurde aumenta la edad, la probabilidad de supervivencia disminuye acorde al estimado de -0.038.

3) Generación de modelos
a.Generar 3 modelos de regresión logística sobre el dataset de entrenamiento utilizando diferentes combinaciones de variables. Al menos dos modelos deben ser multivariados

Actualizamos nuestro objeto formulas:

```{r}
logit_formulas <- formulas(.response = ~ Survived, # único lado derecho de las formulas.
                         pClassSexAge = ~ Pclass + Sex + Age,
                         pClass = ~ Pclass,
                         #Full = ~ Pclass + Sex + Embarked + Fare + Age + SibSp + Parch,
                         pClassSibSpParch = ~ Pclass + SibSp + Parch,
                         sexEmbarkedFare = ~ Sex + Embarked + Fare
                         )
logit_formulas # observamos el objeto formulas
```

Ahora con el objeto fórmulas generamos el data frame con los modelos anidados:

```{r}
models <- data_frame(logit_formulas) %>% # dataframe a partir del objeto formulas
  mutate(models = names(logit_formulas), # columna con los nombres de las formulas
         expression = paste(logit_formulas), # columna con las expresiones de las formulas
         mod = map(logit_formulas, ~glm(., family = 'binomial', data = titanic_split_train))) 
models %>%
    filter(models != "pClassSexAge") #Filtramos el modelo que ya teníamos definido previamente
```

Ahora para desanidar la columna mod:

```{r, message = FALSE, warning = FALSE}
models %>% 
  filter(models != "pClassSexAge") %>% #Filtramos el modelo que ya teníamos definido previamente
  mutate(tidy = map(mod, tidy)) %>% 
  unnest(tidy) %>% 
  mutate(estimate=round(estimate,5), # redondeamos valores para facilitar lectura
         p.value=round(p.value,4))
```

Podemos ver los 3 modelos generados, en el primero de ellos usamos sólamente la variable Pclass, vemos que todos sus coeficientes son significativos, la covariable basal es 1ra clase, para la covariables 2da clase vemos una disminución de la probabilidad de sobrevirir, dado el signo negativo del estimado, para la covariable 3ra clase el coeficiente negativo es aún mayor lo que se interpreta como una posibilidad aún menor de sobrevivir.

El segundo modelo fue elaborado con las variables Pclass, SibSp y Parch, a exepción de la variable SibSp todas las variables son significativas. Se mantiene la disminución de probabilidad de supervivencia al ser de 2da o 3ra clase, dados los coeficientes negativos de estas variables dummies (dadas las demás variables), la variable SipSp también tiene un coeficiente negativo, disminuyendo la probabilidad esperada de sobrevivir, la variable Parch por su parte tiene un coeficiente positivo, con lo que a medida que aumenta aumenta la probabilidad esperada de sobrevivir (dadas las demás variables), esto podría deberse a que dada la premisa mujeres y niños primero, los núcleos familiares con hijos podrían haber tenido prioridad en los botes salvavidas.

El tercer modelo conformado por las variables Sex, Embarked y Fare, cuenta con todas las variables significativas, la variable basal de sexo es "female", vemos en la primera variable dummy Sexmale una disminución significativa de la probabilidad de sobrevivir, con un valor negativo superior a los previamente analizados, el valor basal de la variable Embarked es C de Cherbourg, la variable dummy EmbarquedQ (Queenstown) muestra una disminución de la probabilidad de sobrevivir, por su coeficiente negativo al igual que EmbarquedS (Southampton). Por último la variable Fara cuenta con un coeficiente positivo, que indica que a medida que aumenta el precio del tickete pagado aumenta la probabilidad de sobrevivir, seguramente por que los ticketes de precio altos están asociados a 1ra clase.

b.Ordenar por la deviance los 3 modelos creados en el punto 3)a) y el creado en el punto 2)a) y seleccionar el mejor modelo en términos de la deviance explicada.

```{r}
# Calcular las medidas de evaluación para cada modelo
models <- models %>% 
  mutate(glance = map(mod,glance))
# Obtener las medidas de evaluacion de interes
models %>% 
  unnest(glance) %>%
  # Calculamos la deviance explicada
  mutate(perc_explained_dev = 1-deviance/null.deviance) %>% 
  select(-c(models, df.null, AIC, BIC)) %>% 
  arrange(deviance)
```

Frente al valor de null deviance de 832.5 vemos que el modelo que más reduce la deviance es el modelo con las variables de Pclass, Sex y Age, seguido del modelo de Sex, Embarked y Fare, y del modelo de Pclass, SibSp y Parch, por último el módelo de una sóla variable Pclass es el que logra disminuir menos la deviance, esto también lo podemos ver en la columna de porcentaje explicado de la deviance, donde iniciamos con 0.31 y vamos disminuyendo primro a 0.24 y luego teniendo disminuciones fuertes a 0.08 para los dos últimos modelos, lo que nos indica que estos últimos dos modelos explican realmente muy poco de nuestro caso de estudio.

4) Evaluación del modelo
a.Realizar el gráfico de curva ROC y obtener el AUC para el modelo elegido. Interpretar el gráfico.

```{r, message = FALSE, warning = FALSE}
# Añadir las predicciones
models <- models %>% 
  mutate(pred= map(mod,augment, type.predict = "response"))
#Observaciones con probabilidad más baja
models$pred[1]$pClassSexAge %>% arrange(.fitted) %>% head(10)
```
Vemos las 10 observaciones con menor probabilidad de sobrevivir, en todos los casos, hombres adultos mayores de 3ra clase.

```{r}
#Observaciones con probabilidad más alta
models$pred[1]$pClassSexAge %>% arrange(desc(.fitted)) %>% head(10)
```
Ahora vemos los 10 casos de personas con mayor probabilidad de sobrevivir, todos los casos son mujeres de corta edad, de 1ra clase.

Ahora guardamos los datos del modelo para graficarlo:

```{r, message = FALSE, warning = FALSE}
# Mejor Modelo
prediction_pClassSexAge <- models %>% 
  filter(models == "pClassSexAge") %>% 
  unnest(pred, .drop=TRUE)
prediction_pClassSexAge %>% head(10)
```

Ahora con esta información calculamos la curva ROC.

```{r, message = FALSE, warning = FALSE}
# Calculamos curvas ROC
roc_pClassSexAge <- roc(response=prediction_pClassSexAge$Survived, predictor=prediction_pClassSexAge$.fitted)
ggroc(list(pClassSexAge=roc_pClassSexAge), size=1) + 
  geom_abline(slope = 1, intercept = 1, linetype='dashed') +
  theme_bw() + 
  labs(title='Curva ROC pClassSexAge', color='Modelo')
```


Vemos que la curva está bastante alejada de la diagonal, con lo que veríamos que es un buen modelo. Ahora revisamos el AUC de la curva ROC:

```{r}
print(paste('AUC: Modelo pClassSexAge', round(roc_pClassSexAge$auc,3)))
```
El valor de 0.847 es bastante alto, con lo que nuestro modelo cuenta con un comportamiento global de exactitud alto.

b.Realizar un violin plot e interpretar.

Generamos los gŕaficos de violin plot:

```{r}
# graficamos el modelo completo
ggplot(prediction_pClassSexAge, aes(x=Survived, y=.fitted, group=Survived, fill=factor(Survived))) + 
  geom_violin() +
  theme_bw() +
  guides(fill=FALSE) +
  labs(title='Violin plot', subtitle='Modelo pClassSexAge', y='Predicted probability')
```


Vemos en rojo la distribución de probabilidades de los no sobrevivientes, y en azul la distribución de probabilidades de quienes sobrevivieron. El modelo disctrimina bastanet bien, puesto que las dos distribuciones se ven de algún modo opuestas. Para quienes no sobrevivieron las probabilidades están cerca a 0, para quienes si sobrevivieron las probabilidades están cercanas a 1.

5) Elección del punto corte
a.Sobre el dataset de VALIDACIÓN realizar un gráfico de Accuracy, Specificity, Recall y Precision en función del punto de corte.


```{r}
#titanic_split_test$fitted <- predict.glm(prediction_pClassSexAge, titanic_split_test, type = "response")
#df_val$fitted_2 = predict.glm(m2, df_val, type = "response")
full_model <- glm(logit_formulas$pClassSexAge, family = 'binomial', data = titanic_split_train)
titanic_split_test$.fitted2 <- predict(full_model, newdata =  titanic_split_test, type = "response")

#prediction_pClassSexAge %>% head(10)
#titanic_split_test %>% head(10)

prediction_metrics <- function(cutoff, predictions=titanic_split_test){
  table <- predictions %>% 
    mutate(predicted_class=if_else(.fitted2>cutoff, 1, 0) %>% as.factor(),
           Survived= factor(Survived))
  #str(table$predicted_class)
  #str(table$Survived)
  confusionMatrix(table(table$predicted_class, table$Survived), positive = "1") %>%
    tidy() %>%
    select(term, estimate) %>%
    filter(term %in% c('accuracy', 'sensitivity', 'specificity', 'precision')) %>%
    mutate(cutoff=cutoff)
  
}

cutoffs = seq(0.02,0.95,0.01)
logit_pred= map_dfr(cutoffs, prediction_metrics)%>% mutate(term=as.factor(term))

ggplot(logit_pred, aes(cutoff,estimate, group=term, color=term)) + geom_line(size=1) +
  theme_bw() +
  labs(title= 'Accuracy, Sensitivity, Specificity y Precision', subtitle= 'Modelo prediction_pClassSexAge', color="")


```

Generamos las predicciones en la variable .fitted 2 para nuestra partición de test.

b.Elegir un punto de corte y explicar su decisión.

El punte de corte elegido es 0.54, puesto que es donde vemos que se cruzan la sensitivity y la precisión. Siendo este el punto donde se máximiza del F-Score.

c.Obtener la matriz de confusión con el modelo y punto de corte elegidos. Interpretarla.


```{r}
sel_cutoff = 0.54
# Creamos el modelo de validación
full_model <- glm(logit_formulas$pClassSexAge, family = 'binomial', data = titanic_split_train)
# Agregamos la predicciones al dataset de testeo
table= augment(x=full_model, newdata=titanic_split_test, type.predict='response') 
# Clasificamos utilizamos el punto de corte
table=table %>% 
  mutate(predicted_class=if_else(.fitted>sel_cutoff, 1, 0) %>% as.factor(), 
         default= factor(Survived))
# Creamos la matriz de confusión
confusionMatrix(table(table$predicted_class, table$default), positive = "1")
```

El modelo tiene un acuracy de 78% y de la matriz de confusión podemos ver que clasifica de forma correcta como fallecidos a 134 de los 163 fallecidos, y prediciendo a 73 sobrevivientes de los 103 sobrevivientes.

Se tienen 30 falsos positivos (Error de tipo 1) y 29 falsos negativos (Error de tipo 2).

Vemos que se supera el No Information Rate que representa un predictor ingenuo. El p-valor que tenemos es bastante bajo, con lo que podemos concluír que el acurracy de nuestro modelo es estadísticamente distinto del predictor ingenuo.

La prevalencia de la clase positiva es de poco más del 38%.
De los valores positivos se clasificaron más del 70%, de los valores negativos se clasificaron de forma correcta el 82%.

DATASET DE TESTEO:
6) Evaluación del Modelo
a.Leer el archivo titanic_complete_test.csv y transformar las variables Survived, Pclass y Embarked a factor.

```{r}
#Cargamos el dataset
titanic_test <- read.csv("titanic_complete_test.csv")
#Filtramos las variables a usar
titanic_test <- titanic_test %>% 
  select(PassengerId, Survived, Pclass, Sex, Age, SibSp,Parch, Fare, Embarked)
#Convertimos a factores las varialbes indicadas
titanic_test <- titanic_test %>% 
  mutate(Survived = factor(Survived), Pclass = factor(Pclass), Embarked = factor(Embarked))
summary(titanic_test)
```

Vemos el resumen del dataset con los filtros y las modificaciones de factor indicadas, 9 variables, con distribuciones similares al dataset de training.


b.Con el modelo y punto de corte elegidos clasificar a las personas del dataset de testing.

```{r}
#sel_cutoff = 0.54
# Creamos el modelo de validación
#full_model <- glm(logit_formulas$pClassSexAge, family = 'binomial', data = titanic_split_train)
# Agregamos la predicciones al dataset de testeo
table= augment(x=full_model, newdata=titanic_test, type.predict='response') 
# Clasificamos utilizamos el punto de corte
table=table %>% 
  mutate(predicted_class=if_else(.fitted>sel_cutoff, 1, 0) %>% as.factor(), 
         default= factor(Survived))
table %>% select (Pclass, Sex, Age, Survived, predicted_class)
```

Generados los valores de las predicciones, procederíamos a analizar la matriz de confusión.

c.Obtener la matriz de confusión y comparar con la obtenida en el punto 5)c).

```{r}
# Creamos la matriz de confusión
confusionMatrix(table(table$predicted_class, table$default), positive = "1")
```

Vemos un accuracy del modelo sobre los nuevos datos de 77%, (manteniendo el accuracy del modelo en los datos de validación) el accuracy del modelo ingenuo es de 62% y vemos que el accuracy de nuestro modelo es estadísticamente diferente respecto al modelo ingenuo, esto en el valor tan bajo del p-value.

En cuanto a los valores positivos se predijeron correctamente el 70% (manteniendo el accuracy del modelo en los datos de validación), respecto a los valores negativos tenemos una predicción de 81% (teniendo una mínima disminución del accuracy frente al modelo en los datos de validación que tenía un 82%).








