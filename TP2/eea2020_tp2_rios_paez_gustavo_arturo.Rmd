---
title: 'R Notebook TP 2: Regresión lineal Múltiple'
author: "Gustavo Arturo Ríos Páez"
date: "09 de Novienmbre de 2020"
output:
  html_document:
    df_print: paged
---

CONSIGNAS
El objetivo general es poder crear un modelo lineal simple para explicar el precio de venta de las propiedades en Capital Federal reportadas por la empresa Properati. Para ello es necesario realizar analisis exploratorios, limpieza del dataset y realizar los modelos. Vamos a utilizar datos del 2019 para no incorporar comportamientos atípicos ocasionados por la pandemia del COVID-19.
```{r, message = FALSE, warning = FALSE}
#Añado librerías necesarias
rm( list=ls() )  #remove all objects
gc()             #garbage collection


library(tidyverse)
library(corrr)
library(ggplot2)
library(dplyr)
library(GGally)
library(broom)
library(data.table)
library(tidymodels)
library(gridExtra)
```

1) Preparación de datos
Cargar el dataset de training y realizar una breve descripción del mismo.

```{r}
getwd()
aptosTrain <- fread("ar_properties_train.csv")
#Revisión datos con Glipse
glimpse(aptosTrain)
```

El data set cuenta con 8 variables tenemos una para definir el barrio, otra para la cantidad de habitaciones y baños, otras dos de superficie en metros, tanto total, como cubierta, una variable de precio y por último una propiedad de clasificación por tipo de propiedad.


Vemos un resumen estatístico básico con la función summary:

```{r}
summary(aptosTrain)
```

Vemos que el data set tiene ya un tratamiento de datos, no tiene valores nulos en ninguna de sus 8 variables.
Las habitaciones y baños tienen valores mínimos de 1, y máximos de 8 y 5 respectivamente, lo que hace sentido respecto a el tipo de datos que tenemos en el dataset. La mediana en el caso de las variables bathrooms, surface_total, surface_covered, price, es menor que la media, con lo que tenemos una distribución de datos asimétrica positiva.

La superficie de las propiedades oscila entre 28 y 320 metros, lo que sería representativo de propiedades que podemos encontrar comunmente buscando directamente en la página web. 

```{r}
summary(levels(as.factor(aptosTrain$l3)))
(levels(as.factor(aptosTrain$l3)))

```
La variable l3 correspondería al barrio de la propiedad, con 57 clasificaciones en total, todas ellas parte de Buenos Aires.

```{r}
summary(levels(as.factor(aptosTrain$property_type)))
(levels(as.factor(aptosTrain$property_type)))
```
Los tipos de propiedad se mantienen en Casa, Departamento y PH. Ahora por medio de GGpairs vamos a ver algunas gráficas de las variables, clasificadas por tipo de propiedad:

``````{r, message = FALSE, warning = FALSE}
aptosTrain %>% 
  select(-id,-l3,) %>% # Desestimamos las variables de categóricas que no nos interesan en este punto
  mutate(property_type = factor(property_type)) %>% 
  ggpairs(., 
  title = "GG Pairs por property_type",
  mapping = aes(colour = property_type))
```

En promedio las casas cuentan con más habitaciones que los apartamentos y PHs, los apartamentos y PHstienen ouliers severos en esta variable rooms.
En cuanto a superficie (surface_total y surface_covered) en promedio las casas muestran valores mayores como era de esperarse, sin embargo se tienen outliers marcados para los apartamentos y los PHs. 
Vemos una correlación positiva marcada entre el precio y la superficie, tanto cubierta como total, además de una correlación positiva, pero menor, entre el precio y las variables bathrooms y rooms.

Realizamos un gráfico de boxplot para analizar la variable superficie cubierta:

```{r}
ggplot(aptosTrain, aes(x = property_type, y = surface_covered, group = property_type, fill = property_type))+
  geom_boxplot() +
  scale_y_continuous(limits = c(0, 270)) # definimos escala del eje y
```

En el gráfico vemos que en general las casas cuentan con una mayor superficie respecto a los PHs y los apartamentos, las casas se ven distribuidas de una forma bastante balanceada, mientras que los PHs y los apartamentos tienen asímetría positiva, con outliers marcados superiores. En ninguno de los tres casos vemos outliers inferiores.

Para analizar los precios por tipo de propiedad realizamos un boxplot para esta variable:  

```{r}
ggplot(aptosTrain, aes(x = property_type, y = price, group = property_type, fill = property_type))+
  geom_boxplot() +
  scale_y_continuous(limits = c(0, 1000000)) # definimos escala del eje y
```

Vamos en general un precio mayor para las propiedades de tipo casa, esto se puede explicar dado que son las propiedades de mayor superficie y como vimos previamente el precio está correlacionado positivamente de forma fuerte con la superficie.
En los tres casos vemos distribuciones asímetricas positivas, con gran cantidad de outliers superiores, principalmente para los departamentos, no se observa en ninguno de los tres casos outliers inferiores.

2) Modelo Regresión lineal múltiple
Utilizando el dataset de training:
a.Crear un modelo para predecir el precio con todas las covariables.

Generamos el modalo usando todas las covariables:

```{r}
# ajustamos modelo lineal multiple
modelo_propiedades_l3 <- lm(price ~ bathrooms + rooms + surface_total + surface_covered + property_type + l3, data = aptosTrain)
# Resumen del modelo
tidy_meg_l3 <- tidy(modelo_propiedades_l3, conf.int = TRUE)
tidy_meg_l3
```

b,Analizar los resultados del modelo:
I.Interpretación de los coeficientes estimados

El valor de B0 correspondería a una propiedad de tipo casa en Abasto, con superficie 0 y cantidad de habitaciones 0, es un escenario irreal para el caso de estudio (siendo un valor negativo), sin embargo es el corte en Y, dada la pendiente de la recta de regresión. 

Las variables property_type y l3 generan variables dummies, siendo su categoría basal de property_type "Casa" y la de l3 "Abasto".

El coeficiente estimado de bathrooms de 34mil indica el aumento en el precio de una propiedad si mantenemos fijas las otras covariables, es decir, que para una propiedad de tipo casa, en Abasto, con la misma cantidad de habitaciones y con la misma superficie, por cada baño adicional la propiedad aumentaría en promedio su valor esperado en 34mil.

Acorde a la pendiente definida, las variables categóricas muestras nuevos cortes con el eje Y.
Los valores de las variables dummy de property type, muestran el aumento promedio del valor esperado del precio respecto a los mismos valores de las demás varieables, en caso de comparar una casa con un departamento o con un PH. Para el caso de una propiedad de tipo Departamento tendríamos un aumento promedio de poco más de 91mil, para un PH poco más de 46mil.

El modelo arroja 62 variables, asociadas en su mayoría a las variables dummy de nuestra variable principal l3.
El estimate para la variable bathrooms muestra un incremento de más de 34 mil en el precio, 

II.¿Qué observan respecto de la significatividad de las variables dummy?
Las variables dummy de property_type tienen alta significatividad, las variables dummy surgidas a partir de l3, varian en cuanto a significatividad algunas siendo notablemente significativas.

Vamos a organizar las variables por el p-valor, notamos que las variables bathrooms, surface_covered y l3PuertoMadero (dummy) cuentan con valores tan bajos que son redondeados a 0, sin embargo viendo el estadístico vemos que son las más siginificativas.

```{r}
tidy_meg_l3[order(tidy_meg_l3$p.value),]
```

Ahora vamos a filtrar de las 62 covariables las que nos muestran un p-valor que no sea significativo.

```{r}
tidy_meg_l3 %>% 
  filter(p.value > 0.05)

```

De las 62 covariables vemos que 16 no son significativas, con p-valores menores a 0.05, y con intervalos de confianza que incluyen el 0.
Todas estas 16 covariables son vaiables dummy de la variable l3.

III.Medidas de evaluación del modelo

Los valores analizados hasta ahora nos dan comparativas de a pares, por ejemplo en el caso de las variables dummies, frente a la categoría basal, si queremos entender la significatividad conjunta, necesitamos un test multivariado, como test F de Fisher, prodremos ver sus resultados en la salida de ANOVA.

```{r}
tidy(anova(modelo_propiedades))
```

Los resultados del test nos muestran que acorde al p-valor las variables son estadísticamente significativas, con un valor tan bajo para property_type que es aproximado a 0.

***************************************************************************************************************************

c.Realizar un modelo sin la covariable l3 e interpretar sus resultados (todas las partes de la salida que consideren relevantes).

```{r}
modelo_propiedades <- lm(price ~ surface_covered + bathrooms + rooms + surface_total + property_type, data = aptosTrain)
# Resumen del modelo
tidy_meg <- tidy(modelo_propiedades, conf.int = TRUE)
tidy_meg
```

Ahora graficaremos el precio frente a la superficie cubierta, y generaremos las rectas para la categoria basal casa, y las dos variables dummies de tipo de propiedad, departamento y PH. Todas cuentan con la misma pendiente, sin embargo tienen 3 cortes respecto a Y, y podemos ver como se ajustan mejor para las 3 categorías. 

```{r}
# Accedemos a la información de los coeficientes estimados
intercepto_1 = modelo_propiedades$coefficients[1]
pendiente_meed = modelo_propiedades$coefficients[2]
intercepto = c()
for (i in 6:7) {
  #print(modelo_propiedades$coefficients[i])
  intercepto[i] = modelo_propiedades$coefficients[1] + modelo_propiedades$coefficients[i]
  #print(intercepto[i])
 }

# Graficamos el dataset y el modelo
aptosTrain %>% 
  ggplot(., aes(x = surface_covered, y = price)) + 
  geom_abline(intercept = intercepto_1, slope = pendiente_meed, color = "red", size=1) +
  geom_abline(intercept = intercepto[6], slope = pendiente_meed, color = "forestgreen", size=1) +  
  geom_abline(intercept = intercepto[7], slope = pendiente_meed, color = "blue", size=1) +
  geom_point() +
  theme_bw() +
  scale_x_continuous(limits = c(0,275)) +
  scale_y_continuous(limits = c(0,1000000)) +
  labs(title="Modelo Lineal Múltiple: Superficie cubierta por tipo de propiedad", x="Surface Covered", y="Price") +
  geom_point(aes(colour = factor(property_type)))
```

El modelo sin la covariable l3 es bastante más sencillo en la medida de que cuenta con 6 covariables, de las cuales tenemos en la variable property_type un valor basal para casa, y dos variables dummies para sus otras categorías.
Todos los covariables acorde al p-valor y a los intervalos de confianza, resultan significativos para el modelo.
El intercepto es negativo, lo que no hace sentido para este caso de negocio, sin embargo habría que tener en cuenta que sería el valor para una casa de 0 habitaciones, 0 baños, y 0 metros de superficie.

d.¿Cuál es el modelo que mejor explica la variabilidad del precio?

Vamos a comparar los valores de resumen de cada modelo, enfocaremos la comparación en el R2-ajustado, dado que los modelos no cuentan con la misma cantidad de variables, por lo tanto si nos fijamos sólo en R2, podemos cometer el error de entender el involucramiento de l3 como favorable, cuando sólo se podría deber al aumento en R2 dada la gran cantidad de variables dummies que aporta.


```{r}
#Armamos lista con todos los modelos
models <- list(modelo_propiedades = modelo_propiedades, modelo_propiedades_l3 = modelo_propiedades_l3)
# calculamos las variables resumen
purrr::map_df(models, broom::tidy, .id = "model")
```
Tras esto calculamos las variables de resumen para los dos modelos a comparar:

```{r}
# calculamos las métricas para todos los modelos
df_evaluacion_train = map_df(models, broom::glance, .id = "model") %>%
  # ordenamos por R2 ajustado
  arrange(desc(adj.r.squared))
df_evaluacion_train
```
Tanto el R2 y el R2-Ajustado son mayores en el modelo que incluye l3, con lo que lo hacen un modelo que explica mejor la variabilidad del precio.

3) Creación de variables
Utilizando el dataset de training:

a.En el ejercicio anterior deberían haber encontrado que algunos barrios son significativos, aunque no todos. Crear una nueva variable barrios que permita agrupar a los barrios. Explicar el análisis exploratorio para definir la nueva variable y los criterios utilizados en la construcción de la misma.

Un criterio sugerido es agrupar los barrios según el precio por metro cuadrado promedio de las propiedades ubicadas en ellos, creando grupos de ‘precio_alto’, ‘precio_medio’ y ‘precio_bajo’.


```{r}
#Crear variable precio por m2
aptosTrain_pricem2 <- aptosTrain
aptosTrain_pricem2$pricem2 <- aptosTrain_pricem2$price/aptosTrain_pricem2$surface_total
summary(aptosTrain_pricem2$pricem2)
```
Vemos un boxplot de la variable precio por metro cuadrado para empezar a entenderla:

```{r}
ggplot(aptosTrain_pricem2, aes(y = pricem2, fill = 1)) +
  geom_boxplot(alpha = 0.6)
```

Vemos que en general los precios por metro cuadrado están entre 2mil y 3mil dólares por metro cuadrado, acorde a nuestro primer y tercer cuantil, con la media en 2.7miles de dólares por metro cuadrado, vemos ademas una gran cantidad de ouliers, de los cuales algunos exceden los 10mil dólares por metro cuadrado.


A continuación hacemos un boxplot separando por tipo de propiedad:


```{r}
ggplot(aptosTrain_pricem2, aes(property_type, pricem2, group = property_type, fill = factor(property_type)))+
  geom_boxplot(alpha = 0.6) + 
  theme(legend.position="none")
```
Vemos que los precios por metro cuadrado son en general más bajos en las casas, y más altos en los departamentos, además los precios por metro cuadrado en los departameentos tienen gran parte de los outliers más severos.

Haremos un gráfico de boxplots para visualizar la distribución de los datos por barrio:

```{r}
ggplot(aptosTrain_pricem2, aes(l3, pricem2, group = l3, fill = factor(l3)))+
  geom_boxplot(alpha = 0.6) +
  theme(legend.position="none") +
  coord_flip() 
```
Ahora organizamos la gráfica para poder ver los precios del metro cuadrado organizados por su media:

```{r}
aptosTrain_pricem2$l3 = with(aptosTrain_pricem2, reorder(l3, pricem2, mean))

aptosTrain_pricem2 %>%
ggplot(aes(l3, pricem2, group = l3, fill = factor(l3)))+
  geom_boxplot(alpha = 0.6) +
  theme(legend.position="none") +
  coord_flip() 
```

Basados en los que vemos en el gráfico estableceremos 5 grupos con respecto al precio por metro cuadrado los barrios.
Las agrupaciones serán acorde a los cuartiles, de la siguiente manera para la varible precios por metro cuadrado:

1)<1erQ
2)1erQ-2doQ
3)2doQ-3erQ
4)3Q-3Q+2DE (Entre el 3er cuartil y dos desviaciones estándar)
5)>3Q+2DE (Mayor al 3er cuartil más dos desviaciones estándar)


```{r}
priceQs <- summary(aptosTrain_pricem2$pricem2)
priceQs["IQ Distance"] <- priceQs["Mean"] - priceQs["1st Qu."]
priceQs
#priceQs["1st Qu."]
```

Añadimos el valor de la media de precio por barrio al dataset.

```{r}
aptosTrain_pricem2 <- aptosTrain_pricem2 %>% 
  group_by(l3) %>% 
  mutate(meanBarrios = mean(pricem2))
aptosTrain_pricem2
```

Y basados en este valor generamos la clasificación descrita previamente

```{r}
aptosTrain_pricem2 <- aptosTrain_pricem2 %>%
  mutate(
    barrios = case_when(
      meanBarrios < priceQs["1st Qu."]                               ~ "1Star",
      meanBarrios >= priceQs["1st Qu."] 
      & meanBarrios < priceQs["Mean"]                                ~ "2Star",
      meanBarrios >= priceQs["Mean"] 
      & meanBarrios < priceQs["3rd Qu."]                             ~ "3Star",
      meanBarrios >= priceQs["3rd Qu."] 
      & meanBarrios < (priceQs["3rd Qu."] + 2*priceQs["IQ Distance"]) ~ "4Star",
      meanBarrios > (priceQs["3rd Qu."] + 2*priceQs["IQ Distance"])  ~ "5Star"
    )
  )
head(aptosTrain_pricem2,30)
```
Con esto podemos agrupar la cantidad de barrios de se asociarían a nuestra clasificación de priceLevel del siguiente modo:

```{r}
aptosTrain_pricem2 %>% 
  group_by(barrios) %>%
  count(l3) %>%
  count(barrios)
```

Podemos ver que tenemos un desbalanceo en las clases, con una mayor cantidad de barrios para precios por m2 bajos, y que la cantidad de barrios disminuye a medida que aumentamos en el precio por metro cuadrado, lo que tiene sentido a nivel de negocio, entendiéndolo como que los barrios exclusivos (y costosos), son menos.

Viendo ahora nuestra información de acuerdo a la nueva clasificación:

```{r}
ggplot(aptosTrain_pricem2, aes(barrios, pricem2, group = barrios, fill = factor(barrios)))+
  geom_boxplot(alpha = 0.6)
```

Vemos un salto importante en el precio por metro cuadrado, que ya habíamos evidenciado en nuestro diagrama de boxplot por barrios, para el barrio clasificado como 5Star, que es Puerto Madero.


b.Calcular el modelo que predice el precio en función de las nuevas covariables e interpretar sus resultados (todas las partes de la salida que consideren relevantes).

```{r}
modelo_propiedades_barrios <- lm(price ~ surface_covered + bathrooms + rooms + surface_total + property_type + pricem2 + barrios, data = aptosTrain_pricem2)
# Resumen del modelo
tidy_meg_barrios <- tidy(modelo_propiedades_barrios, conf.int = TRUE)
tidy_meg_barrios
```

En general todas las covariables son significativas acorde al p-valor, a excepción de la variable dummy, barrio3Star, para entender más la significatividad conjunta de la variable barrios, haremos un test ANOVA.

```{r}
tidy(anova(modelo_propiedades_barrios))
```

En él test acorde al resultado del estádistivo de F. y el p-valor vemos que la variable barrios resulta significativa para explicar el precio, al igual que la variable precio por metros cuadrados (pricem2).

c.¿Qué modelo explica mejor la variabilidad de los datos, el que utiliza la variable l3 o el que utiliza barrio? En su opinión, ¿Qué modelo es más útil? ¿Porqué?

Para esto de nuevo generaremos la lista con los modelos a comparar:

```{r}
#Armamos lista con todos los modelos
models <- list(modelo_propiedades = modelo_propiedades ,modelo_propiedades_l3 = modelo_propiedades_l3, modelo_propiedades_barrios = modelo_propiedades_barrios)
# calculamos las variables resumen
purrr::map_df(models, broom::tidy, .id = "model")
```


Ahora generaremos los métricas para los modelos que tenemos, y las organizaremos por el R2-Ajustado 

```{r}
# calculamos las métricas para todos los modelos
df_evaluacion_train = map_df(models, broom::glance, .id = "model") %>%
  # ordenamos por R2 ajustado
  arrange(desc(adj.r.squared))
df_evaluacion_train
```

Al fijarnos en el R2-Ajustado, Vemos que la variabilidad explicada por el modelo de barrios supera ampliamente los dos modelos anteriores. Este modelo sería más útil además, por que cuenta con muchas menos variables, puesto que genera sólo 4 variables dummies, frente a las más de 50 que genera el modelo que incluye l3.


d.La interpretación de los coeficientes de las variables surface_covered y surface_total puede ser un poco problemática ya que se encuentran altamente correlacionadas. Entonces, podemos construir una nueva variable sup_descubierta para la diferencia entre ambas superficies. Calcular nuevamente el modelo lineal del punto 3.b) (modelo con variable barrio) para todas las covariables previas (excepto surface_total), incluyendo surface_covered y sup_descubierta e interpretar los coeficientes de estas dos últimas variables.

```{r}
aptosTrain_pricem2$sup_descubierta <- aptosTrain_pricem2$surface_total - aptosTrain_pricem2$surface_covered

modelo_propiedades_barrios_descubierta <- lm(price ~ surface_covered + bathrooms + rooms + sup_descubierta + property_type + pricem2 + barrios, data = aptosTrain_pricem2)
# Resumen del modelo
tidy_meg_barrios_descubierta <- tidy(modelo_propiedades_barrios_descubierta, conf.int = TRUE)
tidy_meg_barrios_descubierta
```

Vemos que la nueva variable sup_descubierta es significativa para explicar el modelo, su p-valor es realmente bajo, la variable surface_covered sería significativa, con un p-valor muy bajo. El valor del estadístico creción muy notablemente para surface_covered.


4) Diagnóstico del modelo
Utilizando el dataset de training:
Analizar los residuos del modelo elaborado en el punto 3.d) y evaluar el cumplimiento de los supuestos del modelo lineal.

```{r}
#Armamos lista con todos los modelos
models <- list(modelo_propiedades = modelo_propiedades ,modelo_propiedades_l3 = modelo_propiedades_l3, modelo_propiedades_barrios = modelo_propiedades_barrios, modelo_propiedades_barrios_descubierta = modelo_propiedades_barrios_descubierta)
# calculamos las variables resumen
#purrr::map_df(models, broom::tidy, .id = "model")
# calculamos valores predichos para todos los modelos
au_modelos = purrr::map_df(models, broom::augment, .id = "model")
# observamos lo que ocurre con las variables que no se incluyen en el modelo
#au_modelos %>%
#  head(5)
#au_modelos %>%
#  tail(5)
# Modelo barrios con superficie descubierta
g1 = ggplot(au_modelos %>% filter(model == "modelo_propiedades_barrios_descubierta"), 
       aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  labs(title = "Residuos vs valores predichos") + 
  theme_bw()
g2 = ggplot(au_modelos %>% filter(model == "modelo_propiedades_barrios_descubierta"), 
       aes(sample = .std.resid)) +
  stat_qq() +
  geom_abline() +
  labs(title = "Normal QQ plot") + 
  theme_bw()
g3 = ggplot(au_modelos %>% filter(model == "modelo_propiedades_barrios_descubierta"), 
       aes(.fitted, sqrt(abs(.std.resid)))) +
  geom_point() +
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Scale-location plot")
g4 = ggplot(au_modelos %>% filter(model == "modelo_propiedades_barrios_descubierta"), 
       aes(.hat, .std.resid)) +
  geom_vline(size = 2, colour = "white", xintercept = 0) +
  geom_hline(size = 2, colour = "white", yintercept = 0) +
  geom_point() + 
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Residual vs leverage")
# grafico todos juntos
grid.arrange(g1, g2, g3, g4, nrow = 2)
```


Residuos vs valores predichos: Se ve una estructura en los datos, la varianza aumenta, con lo que no es constante, y nos lelva a concluir que parece que no se satisface el supuesto de homocedasticidad.

Normal QQ plot: Tanto el extremo inferior izquierdo como el extremo superior derecho no se ajustan a la distribución teórica.

Residual vs leverage: Existen puntos con un leverage bastante alto.

Diagnóstico del modelo: El modelo que generamos no cumple con los supuestos del modelo lineal. Tenemos problemas de heterocedasticidad, falta de normalidad y presencia de observaciones de alto leverage.

5) Modelo Log(price)
Utilizando el dataset de training:

Crear un modelo para log(price) e interpretar los parámetros estimados de este nuevo modelo. Comparar la performance del modelo de 3.d) con éste, tanto en términos de la variabilidad explicada como del cumplimiento de los supuestos del modelo lineal.

log(price)=β0+β1log(rooms)+β2log(bathrooms)+β3log(surface_covered)+β4property_type+β5barrio+β6surface_patio

Generamos el modelo acorde a la modificación logarítmica:

```{r}
modelo_propiedades_log <- lm(log(price) ~ log(rooms) + log(bathrooms) + log(surface_covered) + property_type + barrios + sup_descubierta, data = aptosTrain_pricem2)
# Resumen del modelo
tidy_meg_log <- tidy(modelo_propiedades_log, conf.int = TRUE)
tidy_meg_log
```
Todas las variables se muestran como significativas para este modelo, algunas con p-valores extremadamente bajos.

Dado que la variable a predecir Y fue tratada con la función logaritmo, tenemos que aplica rla función inversa, para que pueda ser comparable con los demás modelos.

```{r}
modelo_propiedades_log2 <- lm(price ~ log(rooms) + log(bathrooms) + log(surface_covered) + property_type + barrios + sup_descubierta, data = aptosTrain_pricem2)
# Resumen del modelo
tidy_meg_log2 <- tidy(modelo_propiedades_log2, conf.int = TRUE)
tidy_meg_log2
```

Ahora queremos comparar el modelo creado recientemente, sin el logaritmo para precio, con el modelo creado previamente, que incluye la variable de superficie descubierta.

```{r}
models <- list(modelo_propiedades_barrios_descubierta = modelo_propiedades_barrios_descubierta, modelo_propiedades_log2 = modelo_propiedades_log2)

# calculamos las métricas para todos los modelos
df_evaluacion_train = map_df(models, broom::glance, .id = "model") %>%
  # ordenamos por R2 ajustado
  arrange(desc(adj.r.squared))
df_evaluacion_train
```
Vemos que la variabilidad que cubre el modelo en el que no usamos la conversión logarítmica es mucho mayor, con lo que nos restaría validar el cumplimiento de supuestos de linealidad para el modelo donde sí aplicamos dicha conversión logarítmica:

```{r}
# calculamos las variables resumen
#purrr::map_df(models, broom::tidy, .id = "model")
# calculamos valores predichos para todos los modelos
au_modelos = purrr::map_df(models, broom::augment, .id = "model")
# observamos lo que ocurre con las variables que no se incluyen en el modelo
#au_modelos %>%
#  head(5)
#au_modelos %>%
#  tail(5)
# Modelo barrios con superficie descubierta
g1 = ggplot(au_modelos %>% filter(model == "modelo_propiedades_log2"), 
       aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  labs(title = "Residuos vs valores predichos") + 
  theme_bw()
g2 = ggplot(au_modelos %>% filter(model == "modelo_propiedades_log2"), 
       aes(sample = .std.resid)) +
  stat_qq() +
  geom_abline() +
  labs(title = "Normal QQ plot") + 
  theme_bw()
g3 = ggplot(au_modelos %>% filter(model == "modelo_propiedades_log2"), 
       aes(.fitted, sqrt(abs(.std.resid)))) +
  geom_point() +
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Scale-location plot")
g4 = ggplot(au_modelos %>% filter(model == "modelo_propiedades_log2"), 
       aes(.hat, .std.resid)) +
  geom_vline(size = 2, colour = "white", xintercept = 0) +
  geom_hline(size = 2, colour = "white", yintercept = 0) +
  geom_point() + 
  geom_smooth(se = FALSE) + 
  theme_bw() +
  labs(title = "Residual vs leverage")
# grafico todos juntos
grid.arrange(g1, g2, g3, g4, nrow = 2)
```


Normal QQ plot: El extremo inferior izquierdo parece ajustarse un poco mejor, sin embargo el extremo superior derecho no se ajusta a la distribución teórica.

Residual vs leverage: Existen ahora aún más puntos con un leverage bastante alto.

Diagnóstico del modelo: El modelo que generamos no cumple con los supuestos del modelo lineal, falta de normalidad y presencia de observaciones de alto leverage.


6) Selección de modelo
Ahora debe elegir el mejor modelo para predecir los precios de nuevas propiedades.

```{r}
models <- list(modelo_propiedades = modelo_propiedades ,modelo_propiedades_l3 = modelo_propiedades_l3, modelo_propiedades_barrios = modelo_propiedades_barrios, modelo_propiedades_barrios_descubierta = modelo_propiedades_barrios_descubierta, modelo_propiedades_log = modelo_propiedades_log, modelo_propiedades_log2 = modelo_propiedades_log2)
```


Utilizando el dataset de training desarrollar 2 (dos) modelos de regresión múltiple nuevos. Elegir 2 (dos) modelos de los 5 (cinco) que ya fueron creados:

*modelo con todas las covariables
*modelo sin l3
*modelo con la variable barrio
*modelo con la variable sup_descubierta
*modelo con logaritmo.

Puede elegir por los criterios que considere adecuados: métricas, facilidad de interpretación, etc. siempre y cuando los explique claramente

Evalue estos 4 (cuatro) modelos en términos de su capacidad predictiva en el dataset de training, fundamentando claramente su elección con la/s métrica/s que considere adecuada/s.

Predecir los valores de precios de las propiedades en el dataset de testing (recuerden que deben realizar las mismas transformaciones que hicieron en el set de training) y comparar la performance de los modelos seleccionados con la/s métrica/s elegidas previamente. Determinar con cuál modelo se queda y por qué.



***************************************************************************************************************************

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.


***************************************************************************************************************************

